1. 配置文件的格式: 
   <!-- --> : xml文件中的注释格式
   <configuration>  : xml文件中的标签、标记、元素....
        <property>  : 用来表示一个配置项
	     <name></name> : 表示配置项的名称
	     <value></value>: 表示配置项的值
	</property> 
   </configuration>

2. SSH 免密登录
  
  2.1 存在的问题: 集群的启动和关闭,现在都是通过单点启动和关闭的方式操作的。 如果集群的机器很多，怎么办?

  2.2 解决问题的想法: 
      希望把集群启动和关闭的事写成一个脚本.
      
      脚本的大概思路: 
      
      登录到hadoop102  启动/关闭 Namenode 
      登录到hadoop104  启动/关闭 2nn
      登录到hadoop102  hadoop103  hadoop104  启动/关闭  dn
      登录到hadoop103  启动/关闭  rm
      登录到hadoop102  hadoop103 hadoop104  启动/关闭 nm
 
  2.3 如何登录到远程机器
      通过 ssh  ip/主机名
      
  2.4 解决ssh登录到远程机器需要输入密码问题
     
      通过公私钥进行免密登录. 

      实现的效果: hadoop102  hadoop103  hadoop104 之间实现任意免密登录. 
      
      分别在hadoop102  hadoop103 hadoop104 生成公私钥

      ssh-keygen -t rsa  (敲4次回车)

      把hadoop102 hadoop103 hadoop104的公钥授权给别的机器

      ssh-copy-id hadoop102
      ssh-copy-id hadoop103
      ssh-copy-id hadoop104

  
3. 群起集群

   3.1 需要用到的脚本
       start-dfs.sh / stop-dfs.sh
       start-yarn.sh / stop-yarn.sh 
   3.2 hadoop如何知道在哪些机器启动对应的nn  2nn dn rm nm 
       在配置文件中已经指定过 nn  2nn  rm 的地址
       hadoop3需要通过workers文件配置在哪些节点启动dn和nm
       hadoop2的文件是 slaves
   3.3 配置workers
       删除workers文件中的localhost
       添加(无空格无空行)
           hadoop102
	   hadoop103
	   hadoop104
       分发到每个节点

   3.4 群起集群
       启动/关闭 hdfs: 在nn所在的节点运行  start-dfs.sh / stop-dfs.sh
       启动/关闭 yarn: 在rm所在的节点运行  start-yarn.sh /stop-yarn.sh

4. 管理脚本: 
   4.1 实现集群的群起  和  群停 
       脚本名: mycluster.sh
   
   4.2 实现查看每台节点jps的脚本
       脚本名: myjps.sh


5. 历史服务器 
   启动: mapred --daemon start historyserver
   停止: mapred --daemon stop historyserver

6. 日志聚集  
   将Job运行相关的日志上传到HDFS,可以在历史服务器中查看到.

HDFS

1. HDFS: Hadoop Distribute File System  分布式文件系统，由多台机器共同组成的.

2. HDFS优缺点:
   优点:  数据的高可靠(副本机制)    支持处理的数据量很大    可以构建到所谓的廉价服务器(其实一点不廉价)
   缺点:  访问延迟高    对小文件的存储效率低     不支持并发写和文件随机修改

3. HDFS的架构:
   NameNode :  管理元数据  负责处理客户端的读写请求   下达指令给DN
   DataNode :  以块的形式存储真实数据   负责客户端数据的读写操作
   SecondaryNameNode : 为NameNode分担压力， 关键时刻，辅助恢复NameNode
   客户端: Hadoop提供给用户操作HDFS的入口。 
           负责数据的切分(上传数据)
	   通过shell 和 Java API 对HDFS进行操作

4. HDFS文件块大小
   4.1 Hadoop3.1.3 和 Hadoop2.x的块大小默认都是128M
       Hadoop1.x 的块大小默认是64M
       本地模式默认的块大小是32M(后面会说到)
   4.2 块大小通过 dfs.blocksize 进行配置.
       hdfs-default.xml中:
       <property>
	  <name>dfs.blocksize</name>
          <value>134217728</value>
       </property>

   4.3 块大小只是用来衡量一个文件再上传到HDFS的时候，是否需要切分，来决定文件要存成几个块.
       例如: 块大小为128M
       上传一个100M的文件， 最后在HDFS会生成一个块。实际占用空间还是100M
       上传一个200M的文件， 最后在HDFS会生成两个块， 第一个块占用空间128M, 第二个块占用空间72M



作业: 
   1. 完全分布式必须搭建完成(2遍)
   2. 历史服务器  日志聚集   时间同步
   3. HDFS Shell操作多敲多记




















